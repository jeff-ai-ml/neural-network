{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeff-ai-ml/neural-network/blob/main/multi_layer_perceptron_home_price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "7Mszl2EYHgRA"
      },
      "outputs": [],
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"https://raw.githubusercontent.com/jeff-ai-ml/ml-datasets/refs/heads/main/home.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "#print(dataset)\n",
        "X = dataset[:,0:2]\n",
        "Y = dataset[:,2]\n",
        "\n",
        "#print(X)"
      ],
      "metadata": {
        "id": "pK35jltuHi-5"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale inputs\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Scale output (reshape required for scaler)\n",
        "scaler_Y = StandardScaler()\n",
        "Y = scaler_Y.fit_transform(Y.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "0N0IXsOvDsFx"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(3, input_dim=2, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hECj6ciEHm44",
        "outputId": "9a3590c2-318c-4616-d3d0-cc2b46ea7f92"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    if hasattr(layer, 'kernel_initializer'):\n",
        "        print(f\"Layer {i} - {layer.name}:\")\n",
        "        print(\"  Kernel Initializer:\", layer.kernel_initializer)\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulnFmuL42h0",
        "outputId": "8568923b-76f2-4ba3-c508-e977023d3eaa"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 - dense_39:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7e8d88d75c50>\n",
            "\n",
            "Layer 1 - dense_40:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7e8d88daee10>\n",
            "\n",
            "Layer 2 - dense_41:\n",
            "  Kernel Initializer: <keras.src.initializers.random_initializers.GlorotUniform object at 0x7e8d80efe9d0>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
        "#model.compile(optimizer='adam', loss='mse')\n",
        "print(\"\\n📌 Initial Weights:\")\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"Layer {layer.name} weights:\\n\", weights[0])\n",
        "        print(f\"Layer {layer.name} biases:\\n\", weights[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEh4McsuHpgR",
        "outputId": "50be9b0b-f73c-48bc-8bfb-c1e0bd47ca20"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Initial Weights:\n",
            "Layer dense_39 weights:\n",
            " [[ 0.11222506  1.0278723  -0.3226335 ]\n",
            " [ 0.13292396 -0.8053798  -0.8505849 ]]\n",
            "Layer dense_39 biases:\n",
            " [0. 0. 0.]\n",
            "Layer dense_40 weights:\n",
            " [[-0.88409877  0.5400827   0.2138691 ]\n",
            " [ 0.25104618  0.5062475  -0.39439535]\n",
            " [-0.48986483  0.4871633  -0.2804489 ]]\n",
            "Layer dense_40 biases:\n",
            " [0. 0. 0.]\n",
            "Layer dense_41 weights:\n",
            " [[-0.29388416]\n",
            " [ 0.545678  ]\n",
            " [-1.0104827 ]]\n",
            "Layer dense_41 biases:\n",
            " [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
        "#evaluate the model\n",
        "scores = model.evaluate(X_test, Y_test)\n",
        "print(f\"\\nMSE: {scores[1]:.2f}, MAE: {scores[2]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB1KY9cz21N6",
        "outputId": "b0e33cee-6f6d-4caf-fc1e-61fab53a651a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.5806 - mae: 0.6090 - mse: 0.5806\n",
            "Epoch 2/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6122 - mae: 0.6410 - mse: 0.6122\n",
            "Epoch 3/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6121 - mae: 0.6144 - mse: 0.6121\n",
            "Epoch 4/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5615 - mae: 0.5728 - mse: 0.5615\n",
            "Epoch 5/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6131 - mae: 0.6400 - mse: 0.6131\n",
            "Epoch 6/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6810 - mae: 0.6504 - mse: 0.6810\n",
            "Epoch 7/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5913 - mae: 0.6089 - mse: 0.5913\n",
            "Epoch 8/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6539 - mae: 0.6458 - mse: 0.6539\n",
            "Epoch 9/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6896 - mae: 0.6067 - mse: 0.6896\n",
            "Epoch 10/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6413 - mae: 0.5827 - mse: 0.6413\n",
            "Epoch 11/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6744 - mae: 0.6352 - mse: 0.6744\n",
            "Epoch 12/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6991 - mae: 0.6203 - mse: 0.6991\n",
            "Epoch 13/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6611 - mae: 0.6192 - mse: 0.6611\n",
            "Epoch 14/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5890 - mae: 0.6180 - mse: 0.5890\n",
            "Epoch 15/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6056 - mae: 0.6143 - mse: 0.6056\n",
            "Epoch 16/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5688 - mae: 0.6101 - mse: 0.5688\n",
            "Epoch 17/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6167 - mae: 0.5833 - mse: 0.6167\n",
            "Epoch 18/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6203 - mae: 0.6356 - mse: 0.6203\n",
            "Epoch 19/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4676 - mae: 0.5486 - mse: 0.4676\n",
            "Epoch 20/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6874 - mae: 0.6561 - mse: 0.6874\n",
            "Epoch 21/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5325 - mae: 0.5763 - mse: 0.5325 \n",
            "Epoch 22/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6347 - mae: 0.6405 - mse: 0.6347 \n",
            "Epoch 23/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5600 - mae: 0.6138 - mse: 0.5600\n",
            "Epoch 24/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4407 - mae: 0.5261 - mse: 0.4407\n",
            "Epoch 25/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5354 - mae: 0.6058 - mse: 0.5354\n",
            "Epoch 26/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4793 - mae: 0.5439 - mse: 0.4793\n",
            "Epoch 27/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5332 - mae: 0.5973 - mse: 0.5332\n",
            "Epoch 28/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5942 - mae: 0.5909 - mse: 0.5942 \n",
            "Epoch 29/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5725 - mae: 0.6111 - mse: 0.5725\n",
            "Epoch 30/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6233 - mae: 0.6200 - mse: 0.6233\n",
            "Epoch 31/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6581 - mae: 0.6371 - mse: 0.6581\n",
            "Epoch 32/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4842 - mae: 0.5732 - mse: 0.4842\n",
            "Epoch 33/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5890 - mae: 0.6032 - mse: 0.5890\n",
            "Epoch 34/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5647 - mae: 0.6015 - mse: 0.5647\n",
            "Epoch 35/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4458 - mae: 0.5416 - mse: 0.4458\n",
            "Epoch 36/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4539 - mae: 0.5442 - mse: 0.4539\n",
            "Epoch 37/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5155 - mae: 0.5933 - mse: 0.5155 \n",
            "Epoch 38/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4879 - mae: 0.5736 - mse: 0.4879\n",
            "Epoch 39/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5519 - mae: 0.5761 - mse: 0.5519\n",
            "Epoch 40/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6685 - mae: 0.6553 - mse: 0.6685\n",
            "Epoch 41/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6763 - mae: 0.6638 - mse: 0.6763\n",
            "Epoch 42/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6097 - mae: 0.6498 - mse: 0.6097\n",
            "Epoch 43/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4222 - mae: 0.5075 - mse: 0.4222\n",
            "Epoch 44/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4734 - mae: 0.5610 - mse: 0.4734\n",
            "Epoch 45/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5410 - mae: 0.5910 - mse: 0.5410\n",
            "Epoch 46/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5568 - mae: 0.6083 - mse: 0.5568\n",
            "Epoch 47/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5013 - mae: 0.5718 - mse: 0.5013\n",
            "Epoch 48/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5175 - mae: 0.5877 - mse: 0.5175\n",
            "Epoch 49/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4450 - mae: 0.5434 - mse: 0.4450\n",
            "Epoch 50/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5220 - mae: 0.6013 - mse: 0.5220 \n",
            "Epoch 51/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4768 - mae: 0.5874 - mse: 0.4768\n",
            "Epoch 52/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4940 - mae: 0.5621 - mse: 0.4940\n",
            "Epoch 53/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4246 - mae: 0.5426 - mse: 0.4246\n",
            "Epoch 54/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5652 - mae: 0.5891 - mse: 0.5652\n",
            "Epoch 55/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5478 - mae: 0.5905 - mse: 0.5478\n",
            "Epoch 56/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5274 - mae: 0.5966 - mse: 0.5274\n",
            "Epoch 57/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6011 - mae: 0.6394 - mse: 0.6011\n",
            "Epoch 58/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4868 - mae: 0.5847 - mse: 0.4868\n",
            "Epoch 59/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5004 - mae: 0.5851 - mse: 0.5004\n",
            "Epoch 60/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4247 - mae: 0.5484 - mse: 0.4247\n",
            "Epoch 61/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4194 - mae: 0.5570 - mse: 0.4194\n",
            "Epoch 62/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3995 - mae: 0.5234 - mse: 0.3995\n",
            "Epoch 63/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3892 - mae: 0.5232 - mse: 0.3892\n",
            "Epoch 64/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4590 - mae: 0.5586 - mse: 0.4590\n",
            "Epoch 65/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4745 - mae: 0.5638 - mse: 0.4745\n",
            "Epoch 66/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4783 - mae: 0.5801 - mse: 0.4783 \n",
            "Epoch 67/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4118 - mae: 0.5287 - mse: 0.4118 \n",
            "Epoch 68/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4957 - mae: 0.6011 - mse: 0.4957 \n",
            "Epoch 69/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3849 - mae: 0.5102 - mse: 0.3849\n",
            "Epoch 70/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4008 - mae: 0.5328 - mse: 0.4008 \n",
            "Epoch 71/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5217 - mae: 0.6130 - mse: 0.5217 \n",
            "Epoch 72/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4628 - mae: 0.5758 - mse: 0.4628\n",
            "Epoch 73/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4314 - mae: 0.5671 - mse: 0.4314\n",
            "Epoch 74/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5141 - mae: 0.5830 - mse: 0.5141\n",
            "Epoch 75/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4715 - mae: 0.5772 - mse: 0.4715 \n",
            "Epoch 76/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4239 - mae: 0.5447 - mse: 0.4239 \n",
            "Epoch 77/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4191 - mae: 0.5399 - mse: 0.4191 \n",
            "Epoch 78/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3687 - mae: 0.5047 - mse: 0.3687\n",
            "Epoch 79/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4798 - mae: 0.5904 - mse: 0.4798\n",
            "Epoch 80/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4845 - mae: 0.5989 - mse: 0.4845\n",
            "Epoch 81/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3970 - mae: 0.5135 - mse: 0.3970\n",
            "Epoch 82/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4783 - mae: 0.5806 - mse: 0.4783\n",
            "Epoch 83/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4565 - mae: 0.5685 - mse: 0.4565\n",
            "Epoch 84/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3874 - mae: 0.5216 - mse: 0.3874\n",
            "Epoch 85/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3164 - mae: 0.4642 - mse: 0.3164\n",
            "Epoch 86/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4326 - mae: 0.5538 - mse: 0.4326\n",
            "Epoch 87/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4043 - mae: 0.5026 - mse: 0.4043\n",
            "Epoch 88/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4144 - mae: 0.5224 - mse: 0.4144\n",
            "Epoch 89/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4069 - mae: 0.5368 - mse: 0.4069\n",
            "Epoch 90/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4206 - mae: 0.5569 - mse: 0.4206\n",
            "Epoch 91/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4429 - mae: 0.5523 - mse: 0.4429\n",
            "Epoch 92/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4338 - mae: 0.5600 - mse: 0.4338\n",
            "Epoch 93/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4103 - mae: 0.5221 - mse: 0.4103\n",
            "Epoch 94/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3817 - mae: 0.5136 - mse: 0.3817\n",
            "Epoch 95/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3448 - mae: 0.4861 - mse: 0.3448\n",
            "Epoch 96/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3349 - mae: 0.4738 - mse: 0.3349\n",
            "Epoch 97/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3568 - mae: 0.5055 - mse: 0.3568\n",
            "Epoch 98/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3341 - mae: 0.4919 - mse: 0.3341\n",
            "Epoch 99/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3994 - mae: 0.5278 - mse: 0.3994 \n",
            "Epoch 100/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4057 - mae: 0.5342 - mse: 0.4057 \n",
            "Epoch 101/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3414 - mae: 0.4856 - mse: 0.3414 \n",
            "Epoch 102/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3602 - mae: 0.5074 - mse: 0.3602 \n",
            "Epoch 103/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3400 - mae: 0.4941 - mse: 0.3400\n",
            "Epoch 104/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4135 - mae: 0.5525 - mse: 0.4135\n",
            "Epoch 105/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3506 - mae: 0.5074 - mse: 0.3506 \n",
            "Epoch 106/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3888 - mae: 0.5376 - mse: 0.3888 \n",
            "Epoch 107/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3692 - mae: 0.5131 - mse: 0.3692\n",
            "Epoch 108/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3369 - mae: 0.4827 - mse: 0.3369\n",
            "Epoch 109/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3158 - mae: 0.4533 - mse: 0.3158\n",
            "Epoch 110/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3536 - mae: 0.5095 - mse: 0.3536\n",
            "Epoch 111/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3338 - mae: 0.4862 - mse: 0.3338\n",
            "Epoch 112/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3323 - mae: 0.4907 - mse: 0.3323\n",
            "Epoch 113/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2857 - mae: 0.4469 - mse: 0.2857\n",
            "Epoch 114/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3977 - mae: 0.5253 - mse: 0.3977\n",
            "Epoch 115/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3848 - mae: 0.5167 - mse: 0.3848\n",
            "Epoch 116/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3607 - mae: 0.4931 - mse: 0.3607\n",
            "Epoch 117/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3425 - mae: 0.4937 - mse: 0.3425 \n",
            "Epoch 118/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3540 - mae: 0.5018 - mse: 0.3540\n",
            "Epoch 119/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2997 - mae: 0.4477 - mse: 0.2997\n",
            "Epoch 120/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3678 - mae: 0.5039 - mse: 0.3678\n",
            "Epoch 121/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3935 - mae: 0.5148 - mse: 0.3935\n",
            "Epoch 122/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3287 - mae: 0.4865 - mse: 0.3287\n",
            "Epoch 123/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2868 - mae: 0.4476 - mse: 0.2868\n",
            "Epoch 124/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3414 - mae: 0.4796 - mse: 0.3414\n",
            "Epoch 125/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2930 - mae: 0.4545 - mse: 0.2930\n",
            "Epoch 126/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3288 - mae: 0.4729 - mse: 0.3288\n",
            "Epoch 127/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2845 - mae: 0.4440 - mse: 0.2845\n",
            "Epoch 128/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3711 - mae: 0.5224 - mse: 0.3711\n",
            "Epoch 129/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3223 - mae: 0.4735 - mse: 0.3223\n",
            "Epoch 130/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3541 - mae: 0.5032 - mse: 0.3541 \n",
            "Epoch 131/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3591 - mae: 0.5105 - mse: 0.3591\n",
            "Epoch 132/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3688 - mae: 0.4950 - mse: 0.3688\n",
            "Epoch 133/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3363 - mae: 0.4818 - mse: 0.3363\n",
            "Epoch 134/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2984 - mae: 0.4445 - mse: 0.2984\n",
            "Epoch 135/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3387 - mae: 0.4897 - mse: 0.3387\n",
            "Epoch 136/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2749 - mae: 0.4334 - mse: 0.2749\n",
            "Epoch 137/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2831 - mae: 0.4477 - mse: 0.2831\n",
            "Epoch 138/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2625 - mae: 0.4153 - mse: 0.2625\n",
            "Epoch 139/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2984 - mae: 0.4548 - mse: 0.2984\n",
            "Epoch 140/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3077 - mae: 0.4621 - mse: 0.3077\n",
            "Epoch 141/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2460 - mae: 0.4074 - mse: 0.2460 \n",
            "Epoch 142/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2847 - mae: 0.4478 - mse: 0.2847\n",
            "Epoch 143/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3154 - mae: 0.4540 - mse: 0.3154\n",
            "Epoch 144/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3335 - mae: 0.4830 - mse: 0.3335\n",
            "Epoch 145/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2882 - mae: 0.4578 - mse: 0.2882 \n",
            "Epoch 146/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2857 - mae: 0.4378 - mse: 0.2857\n",
            "Epoch 147/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2651 - mae: 0.4361 - mse: 0.2651\n",
            "Epoch 148/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3371 - mae: 0.4895 - mse: 0.3371\n",
            "Epoch 149/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2886 - mae: 0.4438 - mse: 0.2886\n",
            "Epoch 150/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2893 - mae: 0.4397 - mse: 0.2893\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.6095 - mae: 0.6463 - mse: 0.6095\n",
            "\n",
            "MSE: 0.61, MAE: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"Layer: {layer.name}\")\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"  Weights shape: {weights[0].shape}\")\n",
        "        print(f\"  Weights: \\n{weights[0]}\")\n",
        "        print(f\"  Biases shape: {weights[1].shape}\")\n",
        "        print(f\"  Biases: \\n{weights[1]}\")\n",
        "    else:\n",
        "        print(\"  No weights (e.g., Dropout or Flatten layer)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08wMAhU3aMe",
        "outputId": "56219ae6-9046-4910-c2d0-e9b0b237a6cd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: dense_27\n",
            "  Weights shape: (2, 3)\n",
            "  Weights: \n",
            "[[-0.520238    0.59853464  0.47542268]\n",
            " [-0.31195945  0.48228014  0.1046212 ]]\n",
            "  Biases shape: (3,)\n",
            "  Biases: \n",
            "[ 0.0779736  -0.15696946  0.13638376]\n",
            "Layer: dense_28\n",
            "  Weights shape: (3, 3)\n",
            "  Weights: \n",
            "[[-0.24206638 -0.07035996  0.45568544]\n",
            " [ 0.01230264  0.18846393 -0.6028671 ]\n",
            " [-0.9723487   0.59998864 -0.83161515]]\n",
            "  Biases shape: (3,)\n",
            "  Biases: \n",
            "[ 0.         -0.00025655  0.10543218]\n",
            "Layer: dense_29\n",
            "  Weights shape: (3, 1)\n",
            "  Weights: \n",
            "[[ 0.10224271]\n",
            " [ 1.3546197 ]\n",
            " [-1.3101343 ]]\n",
            "  Biases shape: (1,)\n",
            "  Biases: \n",
            "[-0.09926414]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights = model.get_weights()\n",
        "for i, param in enumerate(all_weights):\n",
        "    print(f\"Param {i} shape: {param.shape}\\n{param}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0-uX4K33htm",
        "outputId": "34fae370-2a01-44d9-e846-d2dcc1b269b2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param 0 shape: (2, 3)\n",
            "[[-0.520238    0.59853464  0.47542268]\n",
            " [-0.31195945  0.48228014  0.1046212 ]]\n",
            "\n",
            "Param 1 shape: (3,)\n",
            "[ 0.0779736  -0.15696946  0.13638376]\n",
            "\n",
            "Param 2 shape: (3, 3)\n",
            "[[-0.24206638 -0.07035996  0.45568544]\n",
            " [ 0.01230264  0.18846393 -0.6028671 ]\n",
            " [-0.9723487   0.59998864 -0.83161515]]\n",
            "\n",
            "Param 3 shape: (3,)\n",
            "[ 0.         -0.00025655  0.10543218]\n",
            "\n",
            "Param 4 shape: (3, 1)\n",
            "[[ 0.10224271]\n",
            " [ 1.3546197 ]\n",
            " [-1.3101343 ]]\n",
            "\n",
            "Param 5 shape: (1,)\n",
            "[-0.09926414]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# New house samples\n",
        "samples = np.array([\n",
        "    [1600, 3],   # Sample 1\n",
        "    [1600, 2],   # Sample 2\n",
        "    [1200, 2]    # Sample 3\n",
        "])"
      ],
      "metadata": {
        "id": "ne94Z7xi0heX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the same scaling used during training\n",
        "samples_scaled = scaler.transform(samples)\n",
        "\n",
        "# Predict prices (scaled output)\n",
        "predictions = model.predict(samples_scaled)\n",
        "\n",
        "# Inverse transform to get original price values (scaled value will be less)\n",
        "predictions_unscaled = scaler_Y.inverse_transform(predictions)\n",
        "\n",
        "# Print the unscaled predictions\n",
        "for i, price in enumerate(predictions_unscaled):\n",
        "    print(f\"Sample {i+1} predicted house price: ${price[0]:,.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKzIpAs1042W",
        "outputId": "cc2231f6-49e8-421c-b385-7630c961ea96"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "Sample 1 predicted house price: $280,498.41\n",
            "Sample 2 predicted house price: $249,896.16\n",
            "Sample 3 predicted house price: $230,348.84\n"
          ]
        }
      ]
    }
  ]
}